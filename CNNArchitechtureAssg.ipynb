{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMefmiNE5loqqqpRvFXOdBn"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## CNN Architechture"
      ],
      "metadata": {
        "id": "t5lVgMmgW4OF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Understanding Pooling and Padding in CNN:**\n",
        "\n",
        "1. **Purpose and Benefits of Pooling in CNN:**\n",
        "Pooling in CNNs serves two main purposes: reducing the spatial dimensions (downsampling) of the feature maps and extracting dominant features. By aggregating neighboring pixel values, pooling helps to make the representations more manageable and invariant to small translations in the input data. This aids in capturing the most relevant features while reducing computational complexity and memory requirements.\n",
        "\n",
        "2. **Difference between Max Pooling and Average Pooling:**\n",
        "Max pooling and average pooling are two common types of pooling operations. Max pooling takes the maximum value from each patch of the feature map, emphasizing the most activated features. On the other hand, average pooling computes the average value within each patch, providing a smoother downsampling operation. Max pooling tends to preserve sharper features and is more robust to noise, while average pooling may blur the features but can retain more spatial information.\n",
        "\n",
        "3. **Padding in CNN and its Significance:**\n",
        "Padding is the process of adding extra pixels around the input data before applying convolution operations. Its significance lies in preserving spatial dimensions and information at the borders of the input image. Padding helps to control the spatial size of the output feature maps and ensures that convolutional operations are applied uniformly across the image, preventing loss of information at the edges.\n",
        "\n",
        "5. **Comparison between Zero-padding and Valid-padding:**\n",
        "Zero-padding adds zero-value pixels around the input image, allowing the convolutional operations to be performed at the borders and preserving the spatial dimensions of the input. Valid-padding, on the other hand, means no padding is added, resulting in a reduction of spatial dimensions after convolution. Zero-padding is commonly used to maintain spatial consistency, especially when the size of the filters and strides may reduce the feature map size drastically.\n",
        "\n",
        "---\n",
        "\n",
        "**Exploring LeNet:**\n",
        "\n",
        "1. **Overview of LeNet-5 Architecture:**\n",
        "LeNet-5 is a pioneering convolutional neural network architecture developed by Yann LeCun et al. It consists of seven layers, including two convolutional layers, two subsampling (pooling) layers, and three fully connected layers.\n",
        "\n",
        "2. **Key Components of LeNet-5 and Their Purposes:**\n",
        "- Convolutional Layers: Extract features from the input images using learnable filters.\n",
        "- Subsampling (Pooling) Layers: Downsample the feature maps to reduce spatial dimensions and extract dominant features.\n",
        "- Fully Connected Layers: Perform classification based on the high-level features extracted by the preceding layers.\n",
        "\n",
        "3. **Advantages and Limitations of LeNet-5:**\n",
        "Advantages:\n",
        "- LeNet-5 demonstrated the effectiveness of CNNs for handwritten digit recognition tasks, paving the way for modern CNN architectures.\n",
        "- Its relatively simple architecture and small number of parameters make it efficient for training on small datasets.\n",
        "\n",
        "Limitations:\n",
        "- Limited capacity for handling complex datasets with high variability.\n",
        "- Lack of scalability for deeper architectures and more challenging tasks compared to modern CNNs.\n",
        "\n",
        "4. **Implementation of LeNet-5 and Evaluation:**\n",
        "Implement LeNet-5 using a deep learning framework such as TensorFlow or PyTorch and train it on the MNIST dataset. Evaluate its performance in terms of accuracy and efficiency, and provide insights into its behavior and capabilities.\n"
      ],
      "metadata": {
        "id": "u5wxWiIBb3zY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(X_train_full, y_train_full),(X_test, y_test)=cifar10.load_data()\n",
        "\n",
        "X_train_full=X_train_full/255.0\n",
        "X_test=X_test/255.0\n",
        "\n",
        "y_train_full=to_categorical(y_train_full, num_classes=10)\n",
        "y_test=to_categorical(y_test, num_classes=10)\n",
        "\n",
        "X_valid, X_train=X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train= y_train_full[:5000], y_train_full[5000:]"
      ],
      "metadata": {
        "id": "DX2YI9HPcgFd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import models, layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, BatchNormalization, Activation, Add, AveragePooling2D, Flatten, Dense\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(6, kernel_size = (5,5), padding = 'valid', activation='tanh', input_shape = (32,32,3)))\n",
        "model.add(AveragePooling2D(pool_size= (2,2), strides = 2, padding = 'valid'))\n",
        "\n",
        "model.add(Conv2D(16, kernel_size = (5,5), padding = 'valid', activation='tanh'))\n",
        "model.add(AveragePooling2D(pool_size= (2,2), strides = 2, padding = 'valid'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(120, activation='tanh'))\n",
        "model.add(Dense(84, activation='tanh'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFcwdUdwcgBg",
        "outputId": "0f37c282-2dc7-43e7-8505-08276f3322ee"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " average_pooling2d_6 (Avera  (None, 14, 14, 6)         0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " average_pooling2d_7 (Avera  (None, 5, 5, 16)          0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 120)               48120     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62006 (242.21 KB)\n",
            "Trainable params: 62006 (242.21 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(loss=keras.metrics.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, batch_size=128, epochs=2, verbose=1, validation_data=(X_valid, y_valid))\n",
        "score = model.evaluate(X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Mg06-nScf-x",
        "outputId": "2cb07ed5-5012-49d7-9ad4-2c5dbae88991"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "352/352 [==============================] - 27s 73ms/step - loss: 1.8470 - accuracy: 0.3478 - val_loss: 1.7334 - val_accuracy: 0.3902\n",
            "Epoch 2/2\n",
            "352/352 [==============================] - 25s 72ms/step - loss: 1.6958 - accuracy: 0.4045 - val_loss: 1.6042 - val_accuracy: 0.4324\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.6212 - accuracy: 0.4317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "**Analyzing AlexNet:**\n",
        "\n",
        "1. **Overview of AlexNet Architecture:**\n",
        "AlexNet is a deep convolutional neural network architecture developed by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton. It consists of eight layers, including five convolutional layers, three max-pooling layers, and three fully connected layers.\n",
        "\n",
        "2. **Architectural Innovations in AlexNet:**\n",
        "- Utilization of ReLU activation functions: ReLU helps alleviate the vanishing gradient problem and accelerates training convergence.\n",
        "- Implementation of dropout regularization: Dropout helps prevent overfitting by randomly dropping neurons during training.\n",
        "- Employment of local response normalization (LRN): LRN enhances the generalization ability of the network by normalizing the responses within local regions.\n",
        "\n",
        "3. **Role of Different Layers in AlexNet:**\n",
        "- Convolutional Layers: Extract hierarchical features from input images through learned filters.\n",
        "- Pooling Layers: Downsample feature maps to reduce spatial dimensions and extract dominant features.\n",
        "- Fully Connected Layers: Perform high-level feature extraction and classification.\n",
        "\n",
        "4. **Implementation and Evaluation of AlexNet:**\n",
        "Implement AlexNet using a chosen deep learning framework and evaluate its performance on a dataset of choice. Assess its accuracy, training time, and computational efficiency, providing insights into its effectiveness for various tasks.\n"
      ],
      "metadata": {
        "id": "xnh3wKa0chNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download the data from g drive\n",
        "\n",
        "import gdown\n",
        "url = \"https://drive.google.com/file/d/12jiQxJzYSYl3wnC8x5wHAhRzzJmmsCXP/view?usp=sharing\"\n",
        "file_id = url.split(\"/\")[-2]\n",
        "print(file_id)\n",
        "prefix = 'https://drive.google.com/uc?/export=download&id='\n",
        "gdown.download(prefix+file_id, \"catdog.zip\")\n",
        "\n",
        "\n",
        "! unzip catdog.zip\n",
        "\n",
        "\n",
        "# Set the path to your training and validation data\n",
        "train_data_dir = '/content/train'\n",
        "validation_data_dir = '/content/validation'\n",
        "\n",
        "\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import  preprocess_input\n",
        "\n",
        "\n",
        "# Preprocess the training and validation data\n",
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "\n",
        "batch_size=16\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2l3rRiqlzj4",
        "outputId": "ff9f430b-54be-4215-888b-46b2d13b025d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12jiQxJzYSYl3wnC8x5wHAhRzzJmmsCXP\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?/export=download&id=12jiQxJzYSYl3wnC8x5wHAhRzzJmmsCXP\n",
            "To: /content/catdog.zip\n",
            "100%|██████████| 9.09M/9.09M [00:00<00:00, 128MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  catdog.zip\n",
            "replace train/Cat/0.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: train/Cat/0.jpg         \n",
            "  inflating: train/Cat/1.jpg         \n",
            "  inflating: train/Cat/2.jpg         \n",
            "  inflating: train/Cat/cat.2405.jpg  \n",
            "  inflating: train/Cat/cat.2406.jpg  \n",
            "  inflating: train/Cat/cat.2436.jpg  \n",
            "  inflating: train/Cat/cat.2437.jpg  \n",
            "  inflating: train/Cat/cat.2438.jpg  \n",
            "  inflating: train/Cat/cat.2439.jpg  \n",
            "  inflating: train/Cat/cat.2440.jpg  \n",
            "  inflating: train/Cat/cat.2441.jpg  \n",
            "  inflating: train/Cat/cat.2442.jpg  \n",
            "  inflating: train/Cat/cat.2443.jpg  \n",
            "  inflating: train/Cat/cat.2444.jpg  \n",
            "  inflating: train/Cat/cat.2445.jpg  \n",
            "  inflating: train/Cat/cat.2446.jpg  \n",
            "  inflating: train/Cat/cat.2447.jpg  \n",
            "  inflating: train/Cat/cat.2448.jpg  \n",
            "  inflating: train/Cat/cat.2449.jpg  \n",
            "  inflating: train/Cat/cat.2450.jpg  \n",
            "  inflating: train/Cat/cat.2451.jpg  \n",
            "  inflating: train/Cat/cat.2452.jpg  \n",
            "  inflating: train/Cat/cat.2453.jpg  \n",
            "  inflating: train/Cat/cat.2454.jpg  \n",
            "  inflating: train/Cat/cat.2455.jpg  \n",
            "  inflating: train/Cat/cat.2456.jpg  \n",
            "  inflating: train/Cat/cat.2457.jpg  \n",
            "  inflating: train/Cat/cat.2458.jpg  \n",
            "  inflating: train/Cat/cat.2459.jpg  \n",
            "  inflating: train/Cat/cat.2460.jpg  \n",
            "  inflating: train/Cat/cat.2461.jpg  \n",
            "  inflating: train/Cat/cat.2462.jpg  \n",
            "  inflating: train/Cat/cat.2463.jpg  \n",
            "  inflating: train/Cat/cat.2464.jpg  \n",
            "  inflating: train/Cat/cat.855.jpg   \n",
            "  inflating: train/Cat/cat.856.jpg   \n",
            "  inflating: train/Cat/cat.857.jpg   \n",
            "  inflating: train/Cat/cat.858.jpg   \n",
            "  inflating: train/Cat/cat.859.jpg   \n",
            "  inflating: train/Cat/cat.86.jpg    \n",
            "  inflating: train/Cat/cat.860.jpg   \n",
            "  inflating: train/Cat/cat.861.jpg   \n",
            "  inflating: train/Cat/cat.862.jpg   \n",
            "  inflating: train/Cat/cat.863.jpg   \n",
            "  inflating: train/Cat/cat.864.jpg   \n",
            "  inflating: train/Cat/cat.865.jpg   \n",
            "  inflating: train/Cat/cat.866.jpg   \n",
            "  inflating: train/Cat/cat.867.jpg   \n",
            "  inflating: train/Cat/cat.868.jpg   \n",
            "  inflating: train/Cat/cat.869.jpg   \n",
            "  inflating: train/Cat/cat.87.jpg    \n",
            "  inflating: train/Cat/cat.870.jpg   \n",
            "  inflating: train/Cat/cat.871.jpg   \n",
            "  inflating: train/Cat/cat.872.jpg   \n",
            "  inflating: train/Cat/cat.873.jpg   \n",
            "  inflating: train/Cat/cat.874.jpg   \n",
            "  inflating: train/Cat/cat.875.jpg   \n",
            "  inflating: train/Cat/cat.876.jpg   \n",
            "  inflating: train/Cat/cat.877.jpg   \n",
            "  inflating: train/Cat/cat.878.jpg   \n",
            "  inflating: train/Cat/cat.879.jpg   \n",
            "  inflating: train/Cat/cat.88.jpg    \n",
            "  inflating: train/Cat/cat.880.jpg   \n",
            "  inflating: train/Cat/cat.881.jpg   \n",
            "  inflating: train/Cat/cat.882.jpg   \n",
            "  inflating: train/Cat/cat.883.jpg   \n",
            "  inflating: train/Cat/cat.884.jpg   \n",
            "  inflating: train/Cat/cat.885.jpg   \n",
            "  inflating: train/Cat/cat.886.jpg   \n",
            "  inflating: train/Cat/cat.887.jpg   \n",
            "  inflating: train/Cat/cat.888.jpg   \n",
            "  inflating: train/Cat/cat.889.jpg   \n",
            "  inflating: train/Cat/cat.89.jpg    \n",
            "  inflating: train/Cat/cat.890.jpg   \n",
            "  inflating: train/Cat/cat.891.jpg   \n",
            "  inflating: train/Cat/cat.892.jpg   \n",
            "  inflating: train/Cat/cat.893.jpg   \n",
            "  inflating: train/Cat/cat.894.jpg   \n",
            "  inflating: train/Cat/cat.895.jpg   \n",
            "  inflating: train/Cat/cat.896.jpg   \n",
            "  inflating: train/Cat/cat.897.jpg   \n",
            "  inflating: train/Cat/cat.898.jpg   \n",
            "  inflating: train/Cat/cat.899.jpg   \n",
            "  inflating: train/Cat/cat.9.jpg     \n",
            "  inflating: train/Cat/cat.90.jpg    \n",
            "  inflating: train/Cat/cat.900.jpg   \n",
            "  inflating: train/Cat/cat.901.jpg   \n",
            "  inflating: train/Cat/cat.902.jpg   \n",
            "  inflating: train/Cat/cat.903.jpg   \n",
            "  inflating: train/Cat/cat.904.jpg   \n",
            "  inflating: train/Cat/cat.905.jpg   \n",
            "  inflating: train/Cat/cat.906.jpg   \n",
            "  inflating: train/Cat/cat.907.jpg   \n",
            "  inflating: train/Cat/cat.908.jpg   \n",
            "  inflating: train/Cat/cat.909.jpg   \n",
            "  inflating: train/Cat/cat.91.jpg    \n",
            "  inflating: train/Cat/cat.910.jpg   \n",
            "  inflating: train/Cat/cat.911.jpg   \n",
            "  inflating: train/Cat/cat.912.jpg   \n",
            "  inflating: train/Cat/cat.913.jpg   \n",
            "  inflating: train/Cat/cat.914.jpg   \n",
            "  inflating: train/Cat/cat.915.jpg   \n",
            "  inflating: train/Cat/cat.916.jpg   \n",
            "  inflating: train/Cat/cat.917.jpg   \n",
            "  inflating: train/Cat/cat.918.jpg   \n",
            "  inflating: train/Cat/cat.919.jpg   \n",
            "  inflating: train/Cat/cat.92.jpg    \n",
            "  inflating: train/Cat/cat.920.jpg   \n",
            "  inflating: train/Cat/cat.93.jpg    \n",
            "  inflating: train/Cat/cat.94.jpg    \n",
            "  inflating: train/Cat/cat.946.jpg   \n",
            "  inflating: train/Cat/cat.947.jpg   \n",
            "  inflating: train/Cat/cat.948.jpg   \n",
            "  inflating: train/Cat/cat.949.jpg   \n",
            "  inflating: train/Cat/cat.95.jpg    \n",
            "  inflating: train/Cat/cat.950.jpg   \n",
            "  inflating: train/Cat/cat.951.jpg   \n",
            "  inflating: train/Cat/cat.952.jpg   \n",
            "  inflating: train/Cat/cat.953.jpg   \n",
            "  inflating: train/Cat/cat.954.jpg   \n",
            "  inflating: train/Cat/cat.955.jpg   \n",
            "  inflating: train/Cat/cat.956.jpg   \n",
            "  inflating: train/Cat/cat.957.jpg   \n",
            "  inflating: train/Cat/cat.958.jpg   \n",
            "  inflating: train/Cat/cat.959.jpg   \n",
            "  inflating: train/Cat/cat.96.jpg    \n",
            "  inflating: train/Cat/cat.960.jpg   \n",
            "  inflating: train/Cat/cat.961.jpg   \n",
            "  inflating: train/Cat/cat.962.jpg   \n",
            "  inflating: train/Cat/cat.963.jpg   \n",
            "  inflating: train/Cat/cat.964.jpg   \n",
            "  inflating: train/Cat/cat.965.jpg   \n",
            "  inflating: train/Cat/cat.966.jpg   \n",
            "  inflating: train/Cat/cat.967.jpg   \n",
            "  inflating: train/Cat/cat.968.jpg   \n",
            "  inflating: train/Cat/cat.969.jpg   \n",
            "  inflating: train/Cat/cat.97.jpg    \n",
            "  inflating: train/Cat/cat.970.jpg   \n",
            "  inflating: train/Cat/cat.971.jpg   \n",
            "  inflating: train/Cat/cat.972.jpg   \n",
            "  inflating: train/Cat/cat.973.jpg   \n",
            "  inflating: train/Cat/cat.974.jpg   \n",
            "  inflating: train/Cat/cat.975.jpg   \n",
            "  inflating: train/Cat/cat.976.jpg   \n",
            "  inflating: train/Cat/cat.977.jpg   \n",
            "  inflating: train/Cat/cat.978.jpg   \n",
            "  inflating: train/Cat/cat.979.jpg   \n",
            "  inflating: train/Cat/cat.98.jpg    \n",
            "  inflating: train/Cat/cat.980.jpg   \n",
            "  inflating: train/Cat/cat.981.jpg   \n",
            "  inflating: train/Cat/cat.982.jpg   \n",
            "  inflating: train/Cat/cat.983.jpg   \n",
            "  inflating: train/Cat/cat.984.jpg   \n",
            "  inflating: train/Cat/cat.985.jpg   \n",
            "  inflating: train/Cat/cat.986.jpg   \n",
            "  inflating: train/Cat/cat.987.jpg   \n",
            "  inflating: train/Cat/cat.988.jpg   \n",
            "  inflating: train/Cat/cat.989.jpg   \n",
            "  inflating: train/Cat/cat.99.jpg    \n",
            "  inflating: train/Cat/cat.990.jpg   \n",
            "  inflating: train/Cat/cat.991.jpg   \n",
            "  inflating: train/Cat/cat.992.jpg   \n",
            "  inflating: train/Cat/cat.993.jpg   \n",
            "  inflating: train/Cat/cat.994.jpg   \n",
            "  inflating: train/Cat/cat.995.jpg   \n",
            "  inflating: train/Cat/cat.996.jpg   \n",
            "  inflating: train/Cat/cat.997.jpg   \n",
            "  inflating: train/Cat/cat.998.jpg   \n",
            "  inflating: train/Cat/cat.999.jpg   \n",
            "  inflating: train/Dog/10493.jpg     \n",
            "  inflating: train/Dog/11785.jpg     \n",
            "  inflating: train/Dog/9839.jpg      \n",
            "  inflating: train/Dog/dog.2432.jpg  \n",
            "  inflating: train/Dog/dog.2433.jpg  \n",
            "  inflating: train/Dog/dog.2434.jpg  \n",
            "  inflating: train/Dog/dog.2435.jpg  \n",
            "  inflating: train/Dog/dog.2436.jpg  \n",
            "  inflating: train/Dog/dog.2437.jpg  \n",
            "  inflating: train/Dog/dog.2438.jpg  \n",
            "  inflating: train/Dog/dog.2439.jpg  \n",
            "  inflating: train/Dog/dog.2440.jpg  \n",
            "  inflating: train/Dog/dog.2441.jpg  \n",
            "  inflating: train/Dog/dog.2442.jpg  \n",
            "  inflating: train/Dog/dog.2443.jpg  \n",
            "  inflating: train/Dog/dog.2444.jpg  \n",
            "  inflating: train/Dog/dog.2445.jpg  \n",
            "  inflating: train/Dog/dog.2446.jpg  \n",
            "  inflating: train/Dog/dog.2447.jpg  \n",
            "  inflating: train/Dog/dog.2448.jpg  \n",
            "  inflating: train/Dog/dog.2449.jpg  \n",
            "  inflating: train/Dog/dog.2450.jpg  \n",
            "  inflating: train/Dog/dog.2451.jpg  \n",
            "  inflating: train/Dog/dog.2452.jpg  \n",
            "  inflating: train/Dog/dog.2453.jpg  \n",
            "  inflating: train/Dog/dog.2454.jpg  \n",
            "  inflating: train/Dog/dog.2455.jpg  \n",
            "  inflating: train/Dog/dog.2456.jpg  \n",
            "  inflating: train/Dog/dog.2457.jpg  \n",
            "  inflating: train/Dog/dog.2458.jpg  \n",
            "  inflating: train/Dog/dog.2459.jpg  \n",
            "  inflating: train/Dog/dog.2460.jpg  \n",
            "  inflating: train/Dog/dog.2461.jpg  \n",
            "  inflating: train/Dog/dog.844.jpg   \n",
            "  inflating: train/Dog/dog.845.jpg   \n",
            "  inflating: train/Dog/dog.846.jpg   \n",
            "  inflating: train/Dog/dog.847.jpg   \n",
            "  inflating: train/Dog/dog.848.jpg   \n",
            "  inflating: train/Dog/dog.849.jpg   \n",
            "  inflating: train/Dog/dog.85.jpg    \n",
            "  inflating: train/Dog/dog.850.jpg   \n",
            "  inflating: train/Dog/dog.851.jpg   \n",
            "  inflating: train/Dog/dog.852.jpg   \n",
            "  inflating: train/Dog/dog.853.jpg   \n",
            "  inflating: train/Dog/dog.854.jpg   \n",
            "  inflating: train/Dog/dog.855.jpg   \n",
            "  inflating: train/Dog/dog.856.jpg   \n",
            "  inflating: train/Dog/dog.857.jpg   \n",
            "  inflating: train/Dog/dog.858.jpg   \n",
            "  inflating: train/Dog/dog.859.jpg   \n",
            "  inflating: train/Dog/dog.86.jpg    \n",
            "  inflating: train/Dog/dog.860.jpg   \n",
            "  inflating: train/Dog/dog.861.jpg   \n",
            "  inflating: train/Dog/dog.862.jpg   \n",
            "  inflating: train/Dog/dog.863.jpg   \n",
            "  inflating: train/Dog/dog.864.jpg   \n",
            "  inflating: train/Dog/dog.865.jpg   \n",
            "  inflating: train/Dog/dog.866.jpg   \n",
            "  inflating: train/Dog/dog.867.jpg   \n",
            "  inflating: train/Dog/dog.868.jpg   \n",
            "  inflating: train/Dog/dog.869.jpg   \n",
            "  inflating: train/Dog/dog.87.jpg    \n",
            "  inflating: train/Dog/dog.870.jpg   \n",
            "  inflating: train/Dog/dog.871.jpg   \n",
            "  inflating: train/Dog/dog.872.jpg   \n",
            "  inflating: train/Dog/dog.873.jpg   \n",
            "  inflating: train/Dog/dog.874.jpg   \n",
            "  inflating: train/Dog/dog.875.jpg   \n",
            "  inflating: train/Dog/dog.876.jpg   \n",
            "  inflating: train/Dog/dog.877.jpg   \n",
            "  inflating: train/Dog/dog.878.jpg   \n",
            "  inflating: train/Dog/dog.879.jpg   \n",
            "  inflating: train/Dog/dog.88.jpg    \n",
            "  inflating: train/Dog/dog.880.jpg   \n",
            "  inflating: train/Dog/dog.881.jpg   \n",
            "  inflating: train/Dog/dog.882.jpg   \n",
            "  inflating: train/Dog/dog.883.jpg   \n",
            "  inflating: train/Dog/dog.884.jpg   \n",
            "  inflating: train/Dog/dog.885.jpg   \n",
            "  inflating: train/Dog/dog.886.jpg   \n",
            "  inflating: train/Dog/dog.887.jpg   \n",
            "  inflating: train/Dog/dog.888.jpg   \n",
            "  inflating: train/Dog/dog.889.jpg   \n",
            "  inflating: train/Dog/dog.89.jpg    \n",
            "  inflating: train/Dog/dog.890.jpg   \n",
            "  inflating: train/Dog/dog.891.jpg   \n",
            "  inflating: train/Dog/dog.892.jpg   \n",
            "  inflating: train/Dog/dog.893.jpg   \n",
            "  inflating: train/Dog/dog.894.jpg   \n",
            "  inflating: train/Dog/dog.895.jpg   \n",
            "  inflating: train/Dog/dog.896.jpg   \n",
            "  inflating: train/Dog/dog.897.jpg   \n",
            "  inflating: train/Dog/dog.898.jpg   \n",
            "  inflating: train/Dog/dog.9.jpg     \n",
            "  inflating: train/Dog/dog.90.jpg    \n",
            "  inflating: train/Dog/dog.91.jpg    \n",
            "  inflating: train/Dog/dog.92.jpg    \n",
            "  inflating: train/Dog/dog.93.jpg    \n",
            "  inflating: train/Dog/dog.936.jpg   \n",
            "  inflating: train/Dog/dog.937.jpg   \n",
            "  inflating: train/Dog/dog.938.jpg   \n",
            "  inflating: train/Dog/dog.939.jpg   \n",
            "  inflating: train/Dog/dog.94.jpg    \n",
            "  inflating: train/Dog/dog.940.jpg   \n",
            "  inflating: train/Dog/dog.941.jpg   \n",
            "  inflating: train/Dog/dog.942.jpg   \n",
            "  inflating: train/Dog/dog.943.jpg   \n",
            "  inflating: train/Dog/dog.944.jpg   \n",
            "  inflating: train/Dog/dog.945.jpg   \n",
            "  inflating: train/Dog/dog.946.jpg   \n",
            "  inflating: train/Dog/dog.947.jpg   \n",
            "  inflating: train/Dog/dog.948.jpg   \n",
            "  inflating: train/Dog/dog.949.jpg   \n",
            "  inflating: train/Dog/dog.95.jpg    \n",
            "  inflating: train/Dog/dog.950.jpg   \n",
            "  inflating: train/Dog/dog.951.jpg   \n",
            "  inflating: train/Dog/dog.952.jpg   \n",
            "  inflating: train/Dog/dog.953.jpg   \n",
            "  inflating: train/Dog/dog.954.jpg   \n",
            "  inflating: train/Dog/dog.955.jpg   \n",
            "  inflating: train/Dog/dog.956.jpg   \n",
            "  inflating: train/Dog/dog.957.jpg   \n",
            "  inflating: train/Dog/dog.958.jpg   \n",
            "  inflating: train/Dog/dog.959.jpg   \n",
            "  inflating: train/Dog/dog.96.jpg    \n",
            "  inflating: train/Dog/dog.960.jpg   \n",
            "  inflating: train/Dog/dog.961.jpg   \n",
            "  inflating: train/Dog/dog.962.jpg   \n",
            "  inflating: train/Dog/dog.963.jpg   \n",
            "  inflating: train/Dog/dog.964.jpg   \n",
            "  inflating: train/Dog/dog.965.jpg   \n",
            "  inflating: train/Dog/dog.966.jpg   \n",
            "  inflating: train/Dog/dog.967.jpg   \n",
            "  inflating: train/Dog/dog.968.jpg   \n",
            "  inflating: train/Dog/dog.969.jpg   \n",
            "  inflating: train/Dog/dog.97.jpg    \n",
            "  inflating: train/Dog/dog.970.jpg   \n",
            "  inflating: train/Dog/dog.971.jpg   \n",
            "  inflating: train/Dog/dog.972.jpg   \n",
            "  inflating: train/Dog/dog.973.jpg   \n",
            "  inflating: train/Dog/dog.974.jpg   \n",
            "  inflating: train/Dog/dog.975.jpg   \n",
            "  inflating: train/Dog/dog.976.jpg   \n",
            "  inflating: train/Dog/dog.977.jpg   \n",
            "  inflating: train/Dog/dog.978.jpg   \n",
            "  inflating: train/Dog/dog.979.jpg   \n",
            "  inflating: train/Dog/dog.98.jpg    \n",
            "  inflating: train/Dog/dog.980.jpg   \n",
            "  inflating: train/Dog/dog.981.jpg   \n",
            "  inflating: train/Dog/dog.982.jpg   \n",
            "  inflating: train/Dog/dog.983.jpg   \n",
            "  inflating: train/Dog/dog.984.jpg   \n",
            "  inflating: train/Dog/dog.985.jpg   \n",
            "  inflating: train/Dog/dog.986.jpg   \n",
            "  inflating: train/Dog/dog.987.jpg   \n",
            "  inflating: train/Dog/dog.988.jpg   \n",
            "  inflating: train/Dog/dog.989.jpg   \n",
            "  inflating: train/Dog/dog.99.jpg    \n",
            "  inflating: train/Dog/dog.990.jpg   \n",
            "  inflating: train/Dog/dog.991.jpg   \n",
            "  inflating: train/Dog/dog.992.jpg   \n",
            "  inflating: train/Dog/dog.993.jpg   \n",
            "  inflating: train/Dog/dog.994.jpg   \n",
            "  inflating: train/Dog/dog.995.jpg   \n",
            "  inflating: train/Dog/dog.996.jpg   \n",
            "  inflating: train/Dog/dog.997.jpg   \n",
            "  inflating: train/Dog/dog.998.jpg   \n",
            "  inflating: train/Dog/dog.999.jpg   \n",
            "  inflating: validation/Cat/cat.2407.jpg  \n",
            "  inflating: validation/Cat/cat.2408.jpg  \n",
            "  inflating: validation/Cat/cat.2409.jpg  \n",
            "  inflating: validation/Cat/cat.2410.jpg  \n",
            "  inflating: validation/Cat/cat.2411.jpg  \n",
            "  inflating: validation/Cat/cat.2412.jpg  \n",
            "  inflating: validation/Cat/cat.2413.jpg  \n",
            "  inflating: validation/Cat/cat.2414.jpg  \n",
            "  inflating: validation/Cat/cat.2415.jpg  \n",
            "  inflating: validation/Cat/cat.2416.jpg  \n",
            "  inflating: validation/Cat/cat.2417.jpg  \n",
            "  inflating: validation/Cat/cat.2418.jpg  \n",
            "  inflating: validation/Cat/cat.2419.jpg  \n",
            "  inflating: validation/Cat/cat.2420.jpg  \n",
            "  inflating: validation/Cat/cat.2421.jpg  \n",
            "  inflating: validation/Cat/cat.2422.jpg  \n",
            "  inflating: validation/Cat/cat.2423.jpg  \n",
            "  inflating: validation/Cat/cat.2424.jpg  \n",
            "  inflating: validation/Cat/cat.2425.jpg  \n",
            "  inflating: validation/Cat/cat.2426.jpg  \n",
            "  inflating: validation/Cat/cat.2427.jpg  \n",
            "  inflating: validation/Cat/cat.2428.jpg  \n",
            "  inflating: validation/Cat/cat.2429.jpg  \n",
            "  inflating: validation/Cat/cat.2430.jpg  \n",
            "  inflating: validation/Cat/cat.2431.jpg  \n",
            "  inflating: validation/Cat/cat.2432.jpg  \n",
            "  inflating: validation/Cat/cat.2433.jpg  \n",
            "  inflating: validation/Cat/cat.2434.jpg  \n",
            "  inflating: validation/Cat/cat.2435.jpg  \n",
            "  inflating: validation/Dog/dog.2402.jpg  \n",
            "  inflating: validation/Dog/dog.2403.jpg  \n",
            "  inflating: validation/Dog/dog.2404.jpg  \n",
            "  inflating: validation/Dog/dog.2405.jpg  \n",
            "  inflating: validation/Dog/dog.2406.jpg  \n",
            "  inflating: validation/Dog/dog.2407.jpg  \n",
            "  inflating: validation/Dog/dog.2408.jpg  \n",
            "  inflating: validation/Dog/dog.2409.jpg  \n",
            "  inflating: validation/Dog/dog.2410.jpg  \n",
            "  inflating: validation/Dog/dog.2411.jpg  \n",
            "  inflating: validation/Dog/dog.2412.jpg  \n",
            "  inflating: validation/Dog/dog.2413.jpg  \n",
            "  inflating: validation/Dog/dog.2414.jpg  \n",
            "  inflating: validation/Dog/dog.2415.jpg  \n",
            "  inflating: validation/Dog/dog.2416.jpg  \n",
            "  inflating: validation/Dog/dog.2417.jpg  \n",
            "  inflating: validation/Dog/dog.2418.jpg  \n",
            "  inflating: validation/Dog/dog.2419.jpg  \n",
            "  inflating: validation/Dog/dog.2420.jpg  \n",
            "  inflating: validation/Dog/dog.2421.jpg  \n",
            "  inflating: validation/Dog/dog.2422.jpg  \n",
            "  inflating: validation/Dog/dog.2423.jpg  \n",
            "  inflating: validation/Dog/dog.2424.jpg  \n",
            "  inflating: validation/Dog/dog.2425.jpg  \n",
            "  inflating: validation/Dog/dog.2426.jpg  \n",
            "  inflating: validation/Dog/dog.2427.jpg  \n",
            "  inflating: validation/Dog/dog.2428.jpg  \n",
            "  inflating: validation/Dog/dog.2429.jpg  \n",
            "  inflating: validation/Dog/dog.2430.jpg  \n",
            "  inflating: validation/Dog/dog.2431.jpg  \n",
            "Found 337 images belonging to 2 classes.\n",
            "Found 59 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import MaxPooling2D, Dropout, Activation\n",
        "\n",
        "\n",
        "# Create a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation before passing it to the next layer\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3),strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "#4th Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "# 5th Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "\n",
        "# 1st Dense Layer\n",
        "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd Dense Layer\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cY-VsXMPcpLz",
        "outputId": "cabfdbe8-c83d-45b0-d10a-a9904a5dd7f3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_25 (Conv2D)          (None, 54, 54, 96)        34944     \n",
            "                                                                 \n",
            " activation_24 (Activation)  (None, 54, 54, 96)        0         \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPoolin  (None, 26, 26, 96)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_19 (Ba  (None, 26, 26, 96)        384       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 26, 26, 256)       614656    \n",
            "                                                                 \n",
            " activation_25 (Activation)  (None, 26, 26, 256)       0         \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPooli  (None, 12, 12, 256)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_20 (Ba  (None, 12, 12, 256)       1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 10, 10, 384)       885120    \n",
            "                                                                 \n",
            " activation_26 (Activation)  (None, 10, 10, 384)       0         \n",
            "                                                                 \n",
            " batch_normalization_21 (Ba  (None, 10, 10, 384)       1536      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 8, 8, 384)         1327488   \n",
            "                                                                 \n",
            " activation_27 (Activation)  (None, 8, 8, 384)         0         \n",
            "                                                                 \n",
            " batch_normalization_22 (Ba  (None, 8, 8, 384)         1536      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 6, 6, 256)         884992    \n",
            "                                                                 \n",
            " activation_28 (Activation)  (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPooli  (None, 2, 2, 256)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_23 (Ba  (None, 2, 2, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 4096)              4198400   \n",
            "                                                                 \n",
            " activation_29 (Activation)  (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " batch_normalization_24 (Ba  (None, 4096)              16384     \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 4096)              16781312  \n",
            "                                                                 \n",
            " activation_30 (Activation)  (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " batch_normalization_25 (Ba  (None, 4096)              16384     \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 1)                 4097      \n",
            "                                                                 \n",
            " activation_31 (Activation)  (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24769281 (94.49 MB)\n",
            "Trainable params: 24750145 (94.41 MB)\n",
            "Non-trainable params: 19136 (74.75 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=2,\n",
        "    validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4-lanuBcpH8",
        "outputId": "cffb2fb3-28b4-40c1-b8c4-07154328dc50"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "22/22 [==============================] - 53s 2s/step - loss: 3.7090 - accuracy: 0.4985 - val_loss: 434.8323 - val_accuracy: 0.5085\n",
            "Epoch 2/2\n",
            "22/22 [==============================] - 40s 2s/step - loss: 1.1140 - accuracy: 0.4985 - val_loss: 77.4338 - val_accuracy: 0.5085\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7df84fea9a50>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The End"
      ],
      "metadata": {
        "id": "EoSjHxUwoTXi"
      }
    }
  ]
}